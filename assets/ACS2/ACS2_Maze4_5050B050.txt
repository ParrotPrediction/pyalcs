# beta: 0.05 gamma: 0.95 theta_i: 0.1 theta_e: 0.9 r_ini: 0.5 q_ini:0.5 avt_ini: 0 q_alp_min: 0.5 q_ga_decrease: 0.5
# umax: 100000 doPees: 0 epsilon: 1 prob_exploration_bias: 0.5 exploration bias method: 2 do_action_planning: 0 action_planning_frequency: 50
# do_ga: 1 theta_ga: 100 mu: 0.3 X.type: 2 chi: 0.8 theta_as: 20 theta_exp: 20 do_subsumption: 1
# max_steps: 30000 max_trial_steps: 50 anz_experiments: 20 reward_test: 0 model_test_iteration: 200 reward_test_iteration: 50
Next Experiment
0 0 0 0 0 nan
200 0 134 139 0 0.410072
400 0 295 322 1 0.455745
600 0 475 530 3 0.48467
800 0 664 745 6 0.485738
1000 1.73913 839 947 11 0.503036
1200 2.6087 977 1126 16 0.514654
1400 3.47826 1095 1275 17 0.517745
1600 6.95652 1126 1342 21 0.525242
1800 9.56522 1220 1472 25 0.527514
2000 12.1739 1299 1584 29 0.533854
2200 15.6522 1362 1680 31 0.536607
2400 21.7391 1412 1754 41 0.537913
2600 26.087 1430 1811 47 0.543553
2800 27.8261 1468 1887 52 0.544118
3000 33.0435 1486 1950 61 0.543782
3200 37.3913 1491 1979 72 0.542446
3400 43.4783 1472 1992 82 0.543424
3600 52.1739 1475 2016 101 0.543527
